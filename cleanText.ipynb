{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_path = r\"M:\\Python\\mocnhien\\dataset\\raw_disease_updated.csv\"\n",
    "df = pd.read_csv(fix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Department', 'Symptom', 'Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CleanText\n",
    "\n",
    "As the sentences distribution are messy in some way. The main here idea is to first, remove all dots, truncate all trailing spaces. Then by the \n",
    "logic that all dot must followed by an UpperCased letter, except for the first letter in the sentence \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function before applying\n",
    "text = \"A.A.A. .\"\n",
    "re.sub(pattern=r\"\\.\", repl=\" \", string=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    text = re.sub(pattern=r\"\\.\", repl=\" \", string=text) # Remove dots\n",
    "    text = re.sub(pattern=r\"[~!@#$%^&*()<>?,/'\\\";:\\{\\[\\]\\}+=\\_\\-\\*\\+]\", repl=\"\", string=text) # Remove puncs\n",
    "    text = re.sub(r'[✍☎⌨].*$', '', text) # Remove consultation-related spammy info\n",
    "    text = re.sub(r'(?:[A-ZĐ]{1}(?:\\s*\\.\\s*)){3,}[A-ZĐ]{1}', '', text)# Remove spammy letters like C . H . A . T . Z . A . L . O\n",
    "    \n",
    "    # Filter some noise by hand \n",
    "    text = re.sub(pattern=r\"(Bác sĩ tham vấn thông tin và hỗ trợ khám bệnh)\", repl=\" \", string=text)\n",
    "    text = re.sub(pattern=r\"(Đội ngũ bác sĩ chúng tôi luôn sẵn sàng nghe bạn chia sẻ hãy liên hệ 1900 1246 hoặc hotline 0886006167)\", repl=\" \", string=text)\n",
    "\n",
    "    # Normalize sentences\n",
    "    text = regex.sub(r'(\\p{Lu})', r'. \\1', text) # Adding dot before uppercased letters\n",
    "    text = re.sub(pattern=r\"(  +)\", repl=\" \", string=text) # Remove trailing spaces\n",
    "\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Symptom'] = df['Symptom'].apply(lambda x:cleanText(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the leading dot\n",
    "prefix_dot = df[df['Symptom'].str[0] == '.'].index\n",
    "\n",
    "for idx in prefix_dot:\n",
    "    df.loc[idx, 'Symptom'] = df.loc[idx, 'Symptom'].replace(\".\", \"\", 1).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat duplicate sentences\n",
    "\n",
    "+ Removing duplicated sentences using set. Consider lowercasing all letters for clearer data :>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatSymptom(text):\n",
    "   sentences = set([text.strip().lower() for text in text.split(\".\")])\n",
    "   return ' '.join([sentence for sentence in sentences if sentence is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Symptom'] = df['Symptom'].apply(lambda x: concatSymptom(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unify Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Department'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def LabelUnifier(label):\n",
    "    departments = {\n",
    "    \"Thần kinh - Tâm thần\": [\n",
    "        \"Thần kinh\", \"Nội thần kinh\", \"Ngoại thần kinh\", \"Tâm thần\", \"Tâm lý\"\n",
    "    ],\n",
    "    \"Hô hấp\": [\n",
    "        \"Hô hấp\"\n",
    "    ],\n",
    "    \"Truyền nhiễm\": [\n",
    "        \"Truyền nhiễm\"\n",
    "    ],\n",
    "    \"Tiết niệu - Nam khoa\": [\n",
    "        \"Tiết niệu\", \"Thận tiết niệu\", \"Nam khoa\", \"Nam học\"\n",
    "    ],\n",
    "    \"Nội tiết\": [\n",
    "        \"Nội tiết\", \"Nội tiết chuyển hóa\"\n",
    "    ],\n",
    "    \"Tiêu hóa - Gan mật\": [\n",
    "        \"Tiêu hóa\", \"Tiêu hóa - Gan mật\"\n",
    "    ],\n",
    "    \"Tim mạch - Mạch máu\": [\n",
    "        \"Tim mạch\", \"Mạch máu\"\n",
    "    ],\n",
    "    \"Ung thư\": [\n",
    "        \"Ung thư\", \"Ung bướu\"\n",
    "    ],\n",
    "    \"Di truyền\": [\n",
    "        \"Di truyền\"\n",
    "    ],\n",
    "    \"Răng hàm mặt\": [\n",
    "        \"Răng hàm mặt\"\n",
    "    ],\n",
    "    \"Tai mũi họng\": [\n",
    "        \"Tai mũi họng\"\n",
    "    ],\n",
    "    \"Da liễu\": [\n",
    "        \"Da liễu\", \"Da tóc móng\"\n",
    "    ],\n",
    "    \"Nhãn khoa\": [\n",
    "        \"Mắt\", \"Nhãn khoa\"\n",
    "    ],\n",
    "    \"Cơ xương khớp\": [\n",
    "        \"Cơ xương khớp\"\n",
    "    ],\n",
    "    \"Dị ứng\": [\n",
    "        \"Dị ứng\"\n",
    "    ],\n",
    "    \"Xét nghiệm\": [\n",
    "        \"Xét nghiệm\"\n",
    "    ],\n",
    "    \"Sản phụ khoa\": [\n",
    "        \"Sản phụ khoa\", \"Sức khỏe sinh sản\", \"Hỗ trợ sinh sản ivf\", \"Mang thai\"\n",
    "    ],\n",
    "    \"Máu\": [\n",
    "        \"Máu\", \"Máu miễn dịch\"\n",
    "    ],\n",
    "    \"Ngoại lồng ngực\": [\n",
    "        \"Ngoại lồng ngực\"\n",
    "    ]\n",
    "}\n",
    "    for department, keywords in departments.items():\n",
    "        if label in keywords: return department\n",
    "\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Department'] = df['Department'].apply(lambda x:LabelUnifier(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df['Department'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Symptom', 'Department', 'Category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(fix_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ModelService",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
